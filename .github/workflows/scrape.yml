name: Scrape

on:
  push:
  workflow_dispatch:
  schedule:
  # Daily at 6:23 AM UTC
  - cron: '23 6 * * *'

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    if: ${{ !github.event.repository.is_template }}
    steps:
    - uses: actions/checkout@v4
    - name: Create scrape.sh if it doesn't exist
      run: |
        if [ ! -f "scrape.sh" ]; then
          echo '#!/bin/bash' > scrape.sh
          if [[ "$REPO_DESC" == http://* ]] || [[ "$REPO_DESC" == https://* ]]; then
            echo "./download.sh '$REPO_DESC'" >> scrape.sh
          else
            echo "# ./download.sh 'https://www.example.com/'" >> scrape.sh
          fi
          chmod +x scrape.sh
          echo "Created scrape.sh"
          # And replace README.md
          echo -e "# Scheduled scraper\n\nFor $REPO_DESC" > README.md 
        fi
      env:
        REPO_DESC: ${{ github.event.repository.description }}
    - name: Set up Python 3.13
      uses: actions/setup-python@v5
      with:
        python-version: "3.13"
        cache: "pip"
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    - name: Run the scraper
      run: |
        ./scrape.sh
    - name: Process diffs and analyze new gallery items
      run: |
        python process_diffs.py
    - name: Commit and push
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "${timestamp}" || exit 0
        git pull --rebase
        git push
        
    - name: Trigger publish workflow
      if: success() && steps.commit.outcome == 'success'
      uses: peter-evans/repository-dispatch@v2
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        event-type: publish-event